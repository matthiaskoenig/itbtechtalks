{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads (`threading`) & Processes (`multiprocessing`)\n",
    "- both `threading` and `multiprocessing` module have very similar API.\n",
    "- concept of putting code into workers which are started from the main code\n",
    "\n",
    "## Threads\n",
    "To create a thread one subclasses `threading.Thread` and implement the `__init__` and `run` functions.\n",
    "\n",
    "That is all the code you need to successfully create and instantiate a thread in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "class Worker(threading.Thread):\n",
    "    # Our workers constructor, note the super() method which is vital if we want this\n",
    "    # to function properly\n",
    "    def __init__(self):\n",
    "        super(Worker, self).__init__()\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(10):\n",
    "            print(i)\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "\n",
    "# This initializes ''thread1'' as an instance of our Worker Thread\n",
    "thread1 = Worker()\n",
    "# This is the code needed to run our newly created thread\n",
    "thread1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create multiple threads which work 'pseudo'-parallel, i.e. without blocking each other (asynchronous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "99\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "thread1 = Worker()\n",
    "thread2 = Worker()\n",
    "thread3 = Worker()\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with global interpreter lock (GIL)\n",
    "The `threading` code is not using multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import math\n",
    "\n",
    "class FactorialWorker(threading.Thread):\n",
    "    # Our workers constructor, note the super() method which is vital if we want this\n",
    "    # to function properly\n",
    "    def __init__(self):\n",
    "        super(FactorialWorker, self).__init__()\n",
    "\n",
    "    def run(self):\n",
    "        res = math.factorial(1500000)\n",
    "        \n",
    "        \n",
    "thread1 = FactorialWorker()\n",
    "thread1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = FactorialWorker()\n",
    "thread2 = FactorialWorker()\n",
    "thread3 = FactorialWorker()\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiprocessing\n",
    "The same calculation with `multiprocessing` is able to use multiple cores.\n",
    "- define the worker functions and create multiple processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 0 Process-17\n",
      "Worker: 1 Process-18\n",
      "Worker: 2 Process-19\n",
      "Worker: 3 Process-20\n",
      "Worker: 4 Process-21\n",
      "Worker: 5 Process-22\n",
      "Worker: 1 finished\n",
      "Worker: 3 finished\n",
      "Worker: 0 finished\n",
      "Worker: 4 finished\n",
      "Worker: 5 finished\n",
      "Worker: 2 finished\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    print('Worker:', num, multiprocessing.current_process().name)\n",
    "    res = math.factorial(1500000)\n",
    "    print('Worker:', num, 'finished')\n",
    "    return\n",
    "\n",
    "jobs = []\n",
    "for i in range(6):\n",
    "    p = multiprocessing.Process(target=worker, args=(i,))\n",
    "    jobs.append(p)\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting for processes\n",
    "- To wait until a process has completed its work and exited, use the `join()` method.\n",
    "- Work can be distributed to the processes via arguments to worker functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 doubled to 10 by process id: 21713\n",
      "10 doubled to 20 by process id: 21714\n",
      "15 doubled to 30 by process id: 21719\n",
      "20 doubled to 40 by process id: 21722\n",
      "25 doubled to 50 by process id: 21723\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "from multiprocessing import Process\n",
    " \n",
    "def doubler(number):\n",
    "    \"\"\"\n",
    "    A doubling function that can be used by a process\n",
    "    \"\"\"\n",
    "    result = number * 2\n",
    "    proc = os.getpid()\n",
    "    print('{0} doubled to {1} by process id: {2}'.format(\n",
    "        number, result, proc))\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5, 10, 15, 20, 25]\n",
    "    procs = []\n",
    " \n",
    "    for index, number in enumerate(numbers):\n",
    "        proc = Process(target=doubler, args=(number,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    " \n",
    "    for proc in procs:\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool class\n",
    "The Pool class is used to represent a **pool of worker processes**. \n",
    "\n",
    "It has methods which can allow you to offload tasks to the worker processes. Letâ€™s look at a really simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 40]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    " \n",
    "def doubler(number):\n",
    "    return number * 2\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5, 10, 20]\n",
    "    pool = Pool(processes=3)\n",
    "    print(pool.map(doubler, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data and putting it on the queue\n",
      "data found to be processed: 5\n",
      "10\n",
      "data found to be processed: 10\n",
      "20\n",
      "data found to be processed: 13\n",
      "26\n",
      "data found to be processed: -1\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    " \n",
    "sentinel = -1\n",
    " \n",
    "def creator(data, q):\n",
    "    \"\"\"\n",
    "    Creates data to be consumed and waits for the consumer\n",
    "    to finish processing\n",
    "    \"\"\"\n",
    "    print('Creating data and putting it on the queue')\n",
    "    for item in data:\n",
    "        q.put(item)\n",
    " \n",
    "def my_consumer(q):\n",
    "    \"\"\"\n",
    "    Consumes some data and works on it\n",
    " \n",
    "    In this case, all it does is double the input\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        print('data found to be processed: {}'.format(data))\n",
    "        processed = data * 2\n",
    "        print(processed)\n",
    " \n",
    "        if data is sentinel:\n",
    "            break\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    data = [5, 10, 13, -1]\n",
    "    process_one = Process(target=creator, args=(data, q))\n",
    "    process_two = Process(target=my_consumer, args=(q,))\n",
    "    process_one.start()\n",
    "    process_two.start()\n",
    " \n",
    "    q.close()\n",
    "    q.join_thread()\n",
    " \n",
    "    process_one.join()\n",
    "    process_two.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiprocessing",
   "language": "python",
   "name": "multiprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
